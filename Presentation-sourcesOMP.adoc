= Exemples OMP
Patrick Martineau <patrick.martineau@univ-tours.fr>
v1.0, 2018-03-06
:sectnums:
:imagesdir: ./images
:sourcesdir: ./sources

:toc:

== Les bases

=== Vérification de la compilation par votre compilateur, exemple avec gcc

Soit le source suivant hello-simple.c avec une seule ligne pragma OMP simple.
Vous pouvez compiler classiquement votre code :

[source,sh]
gcc hello-simple.c -o hello-simple

ou bien en demandant l'interprétation des pragma openMP avec :

[source,sh]
gcc -fopenmp hello-simple.c -o hello-simple

Lien sur <<{sourcesdir}/hello-simple.c,hello-simple.c>>.
[source,C]
include::{sourcesdir}/hello-simple.c[]

=== Tirer partie de l'interprétation ou la non interprétation des clauses openMP

Le même code sert donc à la fois à obtenir un code séquentiel et un code parallèle.
C'est un outil important qui permet de séparer :

. la phase de conception et validation du code séquentiel,
. de la phase de transformation en code parallèle (donc vous conservez en permanence la capacité à vérifier que vos modifications n’entraînent pas d'erreur à l'exécution)


=== Augmenter la portée de votre code

Pour permettre de recompiler votre source sous Windows/Linux/MacOS, vous pouvez utiliser le fichier omp_repair.h suivant, à la place de <omp.h>

Lien sur <<{sourcesdir}/omp_repair.h,omp_repair.h>>.
[source,C]
include::{sourcesdir}/omp_repair.h[]

En conclusion

* [*] Je sais compiler un code OMP
* [*] Je tire partie de l'accès au code séquentiel pour *vérifier* mes résultats
* [ ] Je maitrise le degré de parallélisme

== Maitrise du parallélisme

Dans cette partie, on focalise sur la manière de créer des parties pouvant s'exécuter en parallèle.
// des parties exécutées en un seul exemplaire, en précisant par quel thread.

=== Comment spécifier ce qui est parallèle de ce qui ne l'est pas ?

Le premier exemple a pour but de démarrer plusieurs threads en parallèle et de montrer que chacun a une identité propre, puisque chacun affiche un numéro (identifiant) différent.
Chacun a donc une variable privée *iam* qui contient une valeur différente.
//[red]#*(Et ce n'est pas bien !)*#

Lien sur <<{sourcesdir}/hello.c,hello.c>>.
[source,C]
include::{sourcesdir}/hello.c[]

Dans cet exemple, on peut s'étonner de demander à chaque thread de remplir la variable *np* avec le nombre de threads.
Tous les threads obtiennent la même valeur.
On aurait pu utiliser une variable partagée et demander à un seul thread de l'affecter avec le nombre de threads. Malheureusement, cela nous obligerait à synchroniser tous les threads, et donc on perdrait du temps...

Avec l'ajout d'une seule ligne, cet exemple a permis de créer plusieurs threads. Chacun exécute le code entre accolades. Les variables *iam* et *np* sont privées, c'est-à-dire que chaque thread a sa version de ces variables.


L'exemple suivant introduit une variable *b* partagée par plusieurs threads.
Cette variable est donc lue et modifiée simultanément, ou quasi-simultanément, par plusieurs threads.
Ce programme peut donc conduire à un résultat incohérent.

Lien sur <<{sourcesdir}/shared.c,shared.c>>.
[source,C]
include::{sourcesdir}/shared.c[]


Parfois, à l'intérieur d'une section parallèle, il y a une partie qui doit être exécutée une seule fois (par exemple, affecter *np* dans l'exemple <<{sourcesdir}/hello.c,hello.c>>).

Lien sur <<{sourcesdir}/single.c,single.c>>.
[source,C]
include::{sourcesdir}/single.c[]

Remarquons que ce pragma ne permet pas de préciser quel thread réalisera le block de code en question.
On peut considérer que c'est le premier thread qui arrivera sur cette section qui l'exécutera et que les suivants passeront directement aux instructions qui suivent ce block.
De toute manière, tous les threads attendent que celui qui exécute la section ait fini avant de démarrer le code qui suit cette section "single".

L'exemple suivant permet de rapidement créer tous les threads en parallèle mais de définir séparément ce que chaque thread doit faire de son coté.
S'il y a moins de section que de threads créés, alors certains threads se finissent immédiatement car ils n'ont rien à faire.

Lien sur <<{sourcesdir}/sections.c,sections.c>>.
[source,C]
include::{sourcesdir}/sections.c[]


* [*] Je sais créer des threads en parallèle
* [*] Je sais séparer code parallèle et code à exécuter par un seul thread
* [ ] Je maîtrise le partage des données

=== Comment paramétrer le nombres des threads en parallèle

Il y a trois manières d'agir sur le degré de parallélisme :

. Au niveau du shell : la compilation au format parallèle ayant été réalisée, on peut utiliser une variable d'environnement pour préciser le nombre de threads à créer dans *les processus fils* :
[source,sh]
export OMP_NUM_THREADS=8

. Au niveau du processus : au début du code, on peut préciser le degré de parallélisme à utiliser tout le long de l'exécution de ce *processus* :
[source,C]
omp_set_num_threads(NumThreads);

. Au niveau du block : en utilisant une clause du pragma parallel qui permet de préciser le degré de parallélisme pour la *section* parallèle
[source,C]
#pragma omp parallel num_threads(NumTreads)

En conclusion

* [*] Je contrôle le degré de parallélisme

== La synchronisation

Le pragma barrier permet de préciser un point de synchronisation commun à tous les threads au milieu d'une section parallèle.
Tous les threads seront bloqués à ce point du code tant que tous les threads ne sont pas arrivés à ce point.
Un équivalent serait de séparer cette section parallèle en deux sections parallèles successives mais on perdrait les valeurs des données locales.

Lien sur <<{sourcesdir}/barrier.c,barrier.c>>.
[source,C]
include::{sourcesdir}/barrier.c[]



== La concurrence

A partir du moment où plusieurs threads s'exécutent simultanément, le problème est de décider si chaque thread a accès à sa version d'une variable (variable privée) ou si la variable est partagée et tous les threads accèdent à la même case mémoire.
Dans l'exemple suivant, la clause private permet de préciser les variables privées.
En C, par défaut la variable est partagée mais je vous conseille de le préciser avec *shared()*.

Lien sur <<{sourcesdir}/private.c,private.c>>.
[source,C]
include::{sourcesdir}/private.c[]

Dans cet exemple, on remarque que chaque thread n'a pas une initialisation de *b* à 20.
Chaque thread ajoute 1 à 'sa variable *b*'.
Une fois tous les threads achevés, la variable *b* affichée est toujours égale à 20.

Pour préciser la valeur initiale d'une variable privée, on peut affecter celle-ci au début du thread ou utiliser *firstprivate()* pour 'recopier' la valeur présente avant le début de la section parallèle.

Lien sur <<{sourcesdir}/firstprivate.c,firstprivate.c>>.
[source,C]
include::{sourcesdir}/firstprivate.c[]

L'exemple suivant permet d'indiquer quelle valeur sera recopiée dans la variable, une fois les threads parallèles achevés.

Lien sur <<{sourcesdir}/lastprivate.c,lastprivate.c>>.
[source,C]
include::{sourcesdir}/lastprivate.c[]


Dans le cas des variables partagées, on peut rapidement mettre en évidence un problème de cohérence.
Pour celà, il suffit de préciser un nombre de threads important, par exemple 1000, avant l'exécution du programme suivant.

Lien sur <<{sourcesdir}/shared.c,shared.c>>.
[source,C]
include::{sourcesdir}/shared.c[]

Le problème mis en évidence avec ce résultat incohérent est qu'une variable partagée (ici *b*) doit être protégée si on veut que plusieurs threads la modifient.

On a besoin de garantir l'exclusion mutuelle entre plusieurs threads pour réaliser ces modifications.
Deux solutions sont proposées en fonction de la granularité de la section critique (le nombre et la complexité des opérations).
Pour une opération simple :

Lien sur <<{sourcesdir}/atomic.c,atomic.c>>.
[source,C]
include::{sourcesdir}/atomic.c[]

Pour un block d'instructions plus complexe :

Lien sur <<{sourcesdir}/critical.c,critical.c>>.
[source,C]
include::{sourcesdir}/critical.c[]


== Conclusion

Il reste à étudier les exemples suivants.

Pour "déplier" une boucle *for* simplement :

* parallelfor.c
* parallelfor+.c
* schedule.c


Pour consolider un résultat global sur la base de résultats partiels obtenus par les différents threads :

* reduction+.c
* reduction.c

Pour conserver un ordre correspondant à l'ordre séquentiel d'une boucle sur une partie de la section:

* ordered.c
* ordered2.c
